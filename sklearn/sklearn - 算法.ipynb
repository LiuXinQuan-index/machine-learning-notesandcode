{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 1, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 0, 1, 2, 1, 2, 2,\n",
       "        1, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2]),\n",
       " 0.9736842105263158)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 实例化，并且设定参数\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 传入训练集并训练\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "# 对测试集进行预测\n",
    "predict_y = knn.predict(test_x)\n",
    "\n",
    "# 查看测试集的正确率\n",
    "knn_score = knn.score(test_x, test_y)\n",
    "predict_y, knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 1, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 2,\n",
       "        1, 2, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2]),\n",
       " 0.9473684210526315)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bayes = MultinomialNB(alpha = 1)\n",
    "bayes.fit(train_x, train_y)\n",
    "predict_y = bayes.predict(test_x)\n",
    "bayes_score = bayes.score(test_x, test_y)\n",
    "predict_y, bayes_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类模型评估\n",
    "- 准确率\n",
    "- 召回率\n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         9\n",
      "  versicolor       0.88      1.00      0.93        14\n",
      "   virginica       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "result = classification_report(test_y, predict_y, target_names = iris.target_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证与网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上的准确率：\n",
      " 0.9736842105263158 \n",
      "\n",
      "交叉验证中最好的结果：\n",
      " 0.9642010431484116 \n",
      "\n",
      "最好的模型参数是：\n",
      " {'n_neighbors': 5} \n",
      "\n",
      "每个超参数每次交叉验证的结果：\n",
      " {'mean_fit_time': array([0.000657  , 0.00066535, 0.00033236, 0.00066527, 0.00034706]), 'std_fit_time': array([0.00046465, 0.00047047, 0.00047002, 0.00047042, 0.00049081]), 'mean_score_time': array([0.00232728, 0.00265861, 0.0016621 , 0.00232697, 0.00133093]), 'std_score_time': array([0.00046895, 0.00047036, 0.00046991, 0.0012435 , 0.00047013]), 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}, {'n_neighbors': 4}, {'n_neighbors': 5}], 'split0_test_score': array([0.92105263, 0.94736842, 0.97368421, 0.97368421, 0.97368421]), 'split1_test_score': array([0.91891892, 0.91891892, 0.89189189, 0.89189189, 0.91891892]), 'split2_test_score': array([1.        , 0.97297297, 1.        , 1.        , 1.        ]), 'mean_test_score': array([0.94665718, 0.9464201 , 0.95519203, 0.95519203, 0.96420104]), 'std_test_score': array([0.03772912, 0.02207766, 0.04603123, 0.04603123, 0.03377359]), 'rank_test_score': array([4, 5, 2, 2, 1])} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 实例化，并且设定参数\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 其中参数cv是指几折交叉验证\n",
    "gc = GridSearchCV(knn,\n",
    "                  param_grid = {'n_neighbors':[1,2,3,4,5]},\n",
    "                  cv = 3)\n",
    "\n",
    "# 开始交叉验证与网格搜索\n",
    "gc.fit(train_x, train_y)\n",
    "\n",
    "print('测试集上的准确率：\\n', gc.score(test_x, test_y), '\\n')\n",
    "print('交叉验证中最好的结果：\\n', gc.best_score_, '\\n')\n",
    "print('最好的模型参数是：\\n', gc.best_params_, '\\n')\n",
    "print('每个超参数每次交叉验证的结果：\\n', gc.cv_results_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 1, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2,\n",
       "        1, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2]),\n",
       " 0.9473684210526315)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(train_x, train_y)\n",
    "predict_y = tree.predict(test_x)\n",
    "score = tree.score(test_x, test_y)\n",
    "predict_y, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林\n",
    "随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。\n",
    "\n",
    "- 为什么要随机抽样训练集？\n",
    "\n",
    "如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的。\n",
    "\n",
    "- 为什么要有放回地抽样？\n",
    "\n",
    "如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是“有偏的”，都是绝对“片面的”，也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Rforest = RandomForestClassifier()\n",
    "Rforest.fit(train_x, train_y)\n",
    "Rforest.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归\n",
    "正规方程一次性计算得出，只适用于线性模型，小规模数据集\n",
    "- sklearn.linear_model.LinearRegression # 最小二乘法线性回归（正规方程）\n",
    "\n",
    "梯度下降法适用于各种类型的模型\n",
    "- sklearn.linear_model.SGDRegressor # 梯度下降法线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09884092  0.1553833  -0.01983582  0.05397562 -0.24654452  0.2831318\n",
      "  -0.03361899 -0.41196611  0.31347168 -0.27157746 -0.20816501  0.0848551\n",
      "  -0.37203369]] \n",
      " [-0.074848    0.11091426 -0.06123332  0.05689557 -0.17970881  0.30582437\n",
      " -0.03447708 -0.34726406  0.16524678 -0.11326285 -0.19289973  0.08569028\n",
      " -0.34669325]\n",
      "[21.94893302] \n",
      " 21.89017152256554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\anaconda\\anaconda\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "boston = datasets.load_boston()\n",
    "train_x, test_x, train_y, test_y = train_test_split(boston.data, boston.target, test_size = 0.25)\n",
    "scaler_x = StandardScaler()\n",
    "train_x = scaler_x.fit_transform(train_x)\n",
    "test_x = scaler_x.transform(test_x)\n",
    "scaler_y = StandardScaler()\n",
    "train_y = scaler_y.fit_transform(train_y.reshape(-1, 1))\n",
    "test_y = scaler_y.transform(test_y.reshape(-1, 1))\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "SGDlr = SGDRegressor()\n",
    "SGDlr.fit(train_x, train_y)\n",
    "\n",
    "# 优化后的参数\n",
    "print(lr.coef_, '\\n', SGDlr.coef_)\n",
    "\n",
    "# 预测\n",
    "lr_predict_y = lr.predict(test_x)\n",
    "SGDlr_predict_y = SGDlr.predict(test_x)\n",
    "\n",
    "# 反向转换\n",
    "lr_predict_y = scaler_y.inverse_transform(lr_predict_y)\n",
    "SGDlr_predict_y = scaler_y.inverse_transform(SGDlr_predict_y)\n",
    "print(lr_predict_y[0], '\\n', SGDlr_predict_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.706786948436083\n",
      "26.753488061996823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "lr_mse = mean_squared_error(lr_predict_y, scaler_y.inverse_transform(test_y))\n",
    "SGDlr_mse = mean_squared_error(SGDlr_predict_y, scaler_y.inverse_transform(test_y))\n",
    "print(lr_mse)\n",
    "print(SGDlr_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 岭回归\n",
    "带有正则化的线性回归（L2正则化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.8053185462501"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(train_x, train_y)\n",
    "ridge_predict_y = ridge.predict(test_x)\n",
    "ridge_mse = mean_squared_error(scaler_y.inverse_transform(ridge_predict_y), \n",
    "                               scaler_y.inverse_transform(predict_y))\n",
    "ridge_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 2 0 1 2 2 0 0 0 1 2 2 0 0 0 2 1 2 1 1 0 2 0 2 1 1 0 0 0 2 0 2 0 1\n",
      " 2] 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression()\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size = 0.25)\n",
    "lor.fit(train_x, train_y)\n",
    "predict_y = lor.predict(test_x)\n",
    "score = lor.score(test_x, test_y)\n",
    "print(predict_y, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 1 0 2 2 1 0 0 0 2 1 2 0 0 0 2 2 2 2 2 0 2 0 1 2 2 0 0 0 2 0 1 0 2\n",
      " 1] \n",
      " [1 1 1 0 2 0 1 2 2 0 0 0 1 2 2 0 0 0 2 1 1 1 1 0 2 0 2 1 1 0 0 0 2 0 2 0 1\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters = 3)\n",
    "km.fit(train_x)\n",
    "predict_y = km.predict(test_x)\n",
    "print(predict_y, '\\n', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮廓系数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531120813377731"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(test_x, predict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN()\n",
    "dbscan.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
