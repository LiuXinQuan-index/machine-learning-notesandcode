{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 合并\n",
    "### 1.1 拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 5, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用concat方法拼接\n",
    "a = tf.random.normal([3,5,10])\n",
    "b = tf.random.normal([4,5,10])\n",
    "c = tf.concat([a,b], axis = 0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意拼接的维度的长度可以不同，但是其它维度必须相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4]), TensorShape([3, 2, 4]), TensorShape([3, 4, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用stack方式进行拼接\n",
    "a = tf.random.normal([3,4])\n",
    "b = tf.random.normal([3,4])\n",
    "c = tf.stack([a, b], axis = 0)\n",
    "d = tf.stack([a, b], axis = 1)\n",
    "e = tf.stack([a, b], axis = 2)\n",
    "c.shape, d.shape, e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack方式中，进行拼接的数据的形状必须相同。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- concat方式不产生新的维度\n",
    "- stack方式产生新的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([5, 35, 7]),\n",
       " TensorShape([5, 35, 7]),\n",
       " TensorShape([10, 20, 7]),\n",
       " TensorShape([10, 15, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.split方式分割，可以指定分割的维度和分割方式\n",
    "x = tf.random.normal([10,35,7])\n",
    "result_1 = tf.split(x, axis = 0, num_or_size_splits = 2)\n",
    "result_2 = tf.split(x, axis = 1, num_or_size_splits = [20, 15])\n",
    "result_1[0].shape, result_1[1].shape, result_2[0].shape, result_2[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis指定分割维度，num_or_size_splits中，如果是整数，则表示等分成几份，如果是列表，则表示按照列表中的长度对该维度进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.unstack方式切割\n",
    "result_3 = tf.unstack(x, axis = 0)\n",
    "result_4 = tf.unstack(x, axis = 1)\n",
    "len(result_3), len(result_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.unstack方式将指定维度按照长度为1进行切分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据统计\n",
    "### 3.1 范数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=282, shape=(), dtype=float32, numpy=4.0>,\n",
       " <tf.Tensor: id=287, shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: id=291, shape=(), dtype=float32, numpy=1.0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.norm进行范数计算\n",
    "x = tf.ones([2,2])\n",
    "L1 = tf.norm(x, ord = 1)\n",
    "L2 = tf.norm(x, ord = 2)\n",
    "Linf = tf.norm(x, ord = np.inf)\n",
    "L1, L2, Linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ord = 1，计算L1范数\n",
    "- ord = 2，计算L2范数\n",
    "- ord = np.inf，计算无穷范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 最大最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10]),\n",
       " TensorShape([4]),\n",
       " TensorShape([10]),\n",
       " <tf.Tensor: id=361, shape=(), dtype=float32, numpy=2.7056465>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.reduce_max, tf.reduce_min\n",
    "x = tf.random.normal([4, 10])\n",
    "x_max_0 = tf.reduce_max(x, axis = 0)\n",
    "x_max_1 = tf.reduce_max(x, axis = 1)\n",
    "x_min_0 = tf.reduce_min(x, axis = 0)\n",
    "x_max = tf.reduce_max(x)\n",
    "x_max_0.shape, x_max_1.shape, x_min_0.shape, x_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数axis表示计算在哪个维度上的最大值或最小值\n",
    "- 不指定axis时，计算全局的最大值或最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 均值与和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10]),\n",
       " <tf.Tensor: id=375, shape=(), dtype=float32, numpy=0.19448729>,\n",
       " TensorShape([10]),\n",
       " <tf.Tensor: id=379, shape=(), dtype=float32, numpy=7.7794914>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.reduce_mean\n",
    "x_mean_0 = tf.reduce_mean(x, axis = 0)\n",
    "x_mean = tf.reduce_mean(x)\n",
    "x_sum_0 = tf.reduce_sum(x, axis = 0)\n",
    "x_sum = tf.reduce_sum(x)\n",
    "x_mean_0.shape, x_mean, x_sum_0.shape, x_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数axis表示计算在哪个维度上的均值与和\n",
    "- 不指定axis时，计算全局的均值与和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 最大值与最小值的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=389, shape=(10,), dtype=int64, numpy=array([2, 2, 0, 0, 3, 3, 1, 3, 1, 1], dtype=int64)>,\n",
       " <tf.Tensor: id=391, shape=(10,), dtype=int64, numpy=array([3, 3, 1, 3, 1, 1, 0, 0, 0, 3], dtype=int64)>,\n",
       " <tf.Tensor: id=393, shape=(4,), dtype=int64, numpy=array([2, 6, 1, 4], dtype=int64)>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.argmax, tf.argmin\n",
    "max_index_1 = tf.argmax(x, axis = 0)\n",
    "min_index_1 = tf.argmin(x, axis = 0)\n",
    "max_index_2 = tf.argmax(x, axis = 1)\n",
    "max_index_1, min_index_1, max_index_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 张量比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=419, shape=(100,), dtype=int64, numpy=\n",
       "array([1, 7, 9, 0, 6, 9, 5, 2, 8, 6, 5, 7, 1, 0, 7, 4, 0, 2, 5, 8, 2, 4,\n",
       "       0, 8, 4, 6, 4, 1, 1, 2, 3, 6, 1, 1, 3, 5, 1, 7, 8, 8, 9, 8, 5, 1,\n",
       "       2, 9, 1, 7, 9, 1, 0, 1, 8, 3, 7, 7, 8, 0, 6, 6, 8, 5, 3, 4, 6, 7,\n",
       "       0, 6, 5, 5, 8, 9, 3, 8, 7, 5, 3, 5, 9, 7, 7, 2, 7, 4, 2, 8, 4, 3,\n",
       "       3, 1, 6, 2, 5, 1, 6, 1, 9, 9, 3, 7], dtype=int64)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 伪预测值\n",
    "# 得到100个预测样本，对10个类进行预测\n",
    "predict = tf.random.normal([100, 10])\n",
    "\n",
    "# 转换成概率\n",
    "predict = tf.nn.softmax(predict, axis = 1)\n",
    "\n",
    "# 哪个类概率越大，则归为该类\n",
    "predict = tf.argmax(predict, axis = 1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=427, shape=(100,), dtype=int64, numpy=\n",
       "array([0, 2, 4, 5, 0, 7, 2, 7, 4, 7, 1, 1, 8, 3, 4, 9, 1, 1, 7, 8, 0, 4,\n",
       "       2, 3, 9, 5, 3, 4, 6, 3, 3, 1, 0, 5, 3, 0, 0, 6, 4, 8, 2, 5, 7, 0,\n",
       "       8, 4, 9, 8, 5, 0, 5, 2, 7, 8, 1, 0, 3, 7, 1, 9, 7, 2, 7, 1, 3, 1,\n",
       "       1, 8, 5, 8, 0, 3, 9, 5, 7, 8, 7, 9, 1, 9, 8, 0, 4, 5, 8, 8, 0, 2,\n",
       "       0, 7, 1, 5, 7, 6, 7, 2, 5, 0, 9, 4], dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 伪真实值\n",
    "true_value = tf.random.uniform([100], dtype = tf.int64, maxval = 10)\n",
    "true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=428, shape=(100,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.equal比较两个张量中对应位置是否相等\n",
    "result = tf.equal(predict, true_value)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=431, shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将bool型转换成int\n",
    "out = tf.cast(result, dtype = tf.int32)\n",
    "\n",
    "# 统计正确个数\n",
    "correct = tf.reduce_sum(out)\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其它比较函数\n",
    "- 大于 tf.greater\n",
    "- 小于 tf.less\n",
    "- 大于等于 tf.greater_equal\n",
    "- 小于等于tf.less_equal\n",
    "- 不等 tf.not_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 填充\n",
    "对于图片数据的高和宽、序列信号的长度，维度长度可能各不相同。为了方便网络的并行计算，需要将不同长度的数据扩张为相同长度，通常的做法是，在需要补充长度的信号开始或结束处填充足够数量的特定数值，如0，使得填充后的长度满足系统要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=471, shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[3, 1, 4],\n",
       "        [1, 4, 2]],\n",
       "\n",
       "       [[4, 1, 1],\n",
       "        [3, 2, 1]]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform([12], minval = 1, maxval = 5, dtype = tf.int32)\n",
    "x = tf.reshape(x, [2,2,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=475, shape=(3, 2, 5), dtype=int32, numpy=\n",
       "array([[[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[3, 1, 4, 0, 0],\n",
       "        [1, 4, 2, 0, 0]],\n",
       "\n",
       "       [[4, 1, 1, 0, 0],\n",
       "        [3, 2, 1, 0, 0]]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.pad方式进行填充\n",
    "y = tf.pad(x, paddings = [[1,0],[0,0],[0,2]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paddings参数是一个嵌套list参数\n",
    "- [1,0]表示在第一个维度的开始填充一个单元，右边不填充\n",
    "- [0,0]表示在第二个维度不进行填充\n",
    "- [0,2]表示在第三个维度的右边填充两个单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2,  3,  5,  6,  3,  2,  5,  5,  4],\n",
       "        [ 0,  0,  3,  4,  5,  6,  2, 24,  5]]),\n",
       " array([[ 1,  2,  3,  5,  6,  3,  2,  5,  5],\n",
       "        [ 3,  4,  5,  6,  2, 24,  5,  0,  0]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以通过下面的方法进行自动填充，使长度相等\n",
    "a = [[1,2,3,5,6,3,2,5,5,4],[3,4,5,6,2,24,5]]\n",
    "train = tf.keras.preprocessing.sequence.pad_sequences(a, maxlen = 9, value = 0)\n",
    "train_2 = tf.keras.preprocessing.sequence.pad_sequences(a, maxlen = 9, \\\n",
    "                                                        truncating = 'post', \\\n",
    "                                                        padding = 'post')\n",
    "train, train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "truncating和padding参数\n",
    "- post是指截断和填充在后面\n",
    "- pre是指截断和填充在前面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 数据限幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=497, shape=(5,), dtype=int32, numpy=array([3, 3, 3, 3, 4])>,\n",
       " <tf.Tensor: id=499, shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 3])>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.maximum, tf.minimum\n",
    "x = tf.range(5)\n",
    "a = tf.maximum(x, 3)\n",
    "b = tf.minimum(x, 3)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.maximum实现对大于指定上限的数据，都让其等于指定数据\n",
    "- tf.minimum实现对小于指定下限的数据，都让其等于指定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=507, shape=(5,), dtype=int32, numpy=array([2, 2, 2, 3, 3])>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.clip_by_value实现上下限幅\n",
    "c = tf.clip_by_value(x, 2, 3)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
