{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 索引与切片\n",
    "### 1.1 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=39, shape=(3,), dtype=float32, numpy=array([-0.51165336, -1.8729898 , -0.13762352], dtype=float32)>,\n",
       " <tf.Tensor: id=43, shape=(3,), dtype=float32, numpy=array([-0.51165336, -1.8729898 , -0.13762352], dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建4张32*32大小的彩色图片数据\n",
    "x = tf.random.normal([4, 32, 32, 3])\n",
    "\n",
    "# 使用基本索引的方式\n",
    "a = x[1][2][10]\n",
    "\n",
    "# 使用tensorflow支持的方式\n",
    "b = x[1, 2, 10]\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start:end:step\n",
    "c = x[0:3:2, 10:20, 10:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 4, 4, 2]),\n",
       " TensorShape([2, 4, 4, 2]),\n",
       " TensorShape([2, 4, 4, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取1-2张图片的G/B通道\n",
    "d = x[1:2, ..., 1:]\n",
    "\n",
    "# 读取所有照片的G/B通道\n",
    "e = x[..., 1:]\n",
    "\n",
    "# 读取1-2张图片的所有数据\n",
    "f = x[0:2, ...]\n",
    "\n",
    "d.shape, e.shape, f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 维度变换\n",
    "### 2.1 Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变维度\n",
    "x = tf.range(96)\n",
    "x = tf.reshape(x, [2, 4, 4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在改变维度时，我们需要了解数据的写入顺序，如果写入顺序错误，则改变维度后可能得到错误的结果。\n",
    "\n",
    "比如正确的特征写入顺序为a-b-c-d，这样我们得到一个一维的向量，将其按照[2, 4, 4, 3]reshpae后，得到正确的结果。\n",
    "\n",
    "但是如果写入顺序为a-c-b-d，虽然也能得到一个一维向量，但是按照[2, 4, 4, 3]reshape后，得到的结果并不正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, TensorShape([2, 4, 4, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看维度数量和形状\n",
    "x.ndim, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果有一个维度的长度不知道，或者懒得计算\n",
    "# 可以用-1，让计算机自动计算该维度的长度\n",
    "x = tf.reshape(x, [2, 3, -1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面计算机自动将最后一个维度的长度计算出来，为16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 增删维度\n",
    "无论是增加一个维度还是删除一个维度，增加和删除的维度长度必须为1，因此并不改变数据的存储，只是改变数据的理解方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 1, 16)\n",
      "(2, 3, 16)\n"
     ]
    }
   ],
   "source": [
    "# 增加维度，axis = 2说明在第二个维度后面增加一个维度\n",
    "x = tf.expand_dims(x, axis = 2)\n",
    "print(x.shape)\n",
    "\n",
    "# 删除刚才增加的维度，axis = 2说明删除第二个维度后面的维度\n",
    "x = tf.squeeze(x, axis = 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3, 16)\n",
      "(2, 3, 16)\n"
     ]
    }
   ],
   "source": [
    "# 增加维度，axis = -3说明从后往前数，在第三个位置增加一个维度\n",
    "x = tf.expand_dims(x, axis = -3)\n",
    "print(x.shape)\n",
    "\n",
    "# 删除刚才增加的维度，axis = -3说明从后往前数，删除第三个位置的维度\n",
    "x = tf.squeeze(x, axis = -3)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果squeeze不指定维度，将删除所有长度为1的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 交换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 23, 23, 3]), TensorShape([2, 3, 23, 23]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.random.normal([2, 23, 23, 3])\n",
    "x2 = tf.transpose(x1, perm = [0, 3, 1, 2])\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1是原始的维度排列方式，如果将原始的维度排列方式按照顺序编号，即0，1，2，3。我们在tf.transpose方法中，参数perm表示将原始维度按照perm的编号重新进行排列，上面的例子是将第4个维度放在第二的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 数据复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=135, shape=(2, 2), dtype=int32, numpy=\n",
       " array([[0, 1],\n",
       "        [2, 3]])>,\n",
       " <tf.Tensor: id=137, shape=(2, 4), dtype=int32, numpy=\n",
       " array([[0, 1, 0, 1],\n",
       "        [2, 3, 2, 3]])>,\n",
       " <tf.Tensor: id=139, shape=(4, 4), dtype=int32, numpy=\n",
       " array([[0, 1, 0, 1],\n",
       "        [2, 3, 2, 3],\n",
       "        [0, 1, 0, 1],\n",
       "        [2, 3, 2, 3]])>,\n",
       " <tf.Tensor: id=141, shape=(4, 6), dtype=int32, numpy=\n",
       " array([[0, 1, 0, 1, 0, 1],\n",
       "        [2, 3, 2, 3, 2, 3],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [2, 3, 2, 3, 2, 3]])>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "x = tf.reshape(x, [2,2])\n",
    "\n",
    "# 在列方向上复制一次数据\n",
    "x1 = tf.tile(x, multiples = [1,2])\n",
    "\n",
    "# 在行方向上再复制一次数据\n",
    "x2 = tf.tile(x1, multiples = [2,1])\n",
    "\n",
    "# 当然也可以进行多次复制\n",
    "x3 = tf.tile(x, [2,3])\n",
    "x, x1, x2, x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 4]), TensorShape([4]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(12)\n",
    "a = tf.reshape(a, [3, 4])\n",
    "b = tf.range(4)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了一个3*4的矩阵和一个长度为4的向量，当两个矩阵的形状不一样时，应该是不能相加的，但是在broadcasting机制下，相加成功了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=152, shape=(3, 4), dtype=int32, numpy=\n",
       "array([[ 0,  2,  4,  6],\n",
       "       [ 4,  6,  8, 10],\n",
       "       [ 8, 10, 12, 14]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是为什么呢？对于b来说，它实际上是一个[1, 4]的矩阵，broadcasting可以将长度维1的维度自动扩展到与其运算的另一个矩阵的长度，来完成运算，也就是将b扩展成了[3, 4]的矩阵，扩展出来的长度中保存的是原始数据的复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=154, shape=(3, 4), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 3],\n",
       "       [0, 1, 2, 3],\n",
       "       [0, 1, 2, 3]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过tf.broadcast_to，可以将矩阵b扩展到与a相同的形状\n",
    "B = tf.broadcast_to(b, a.shape)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=165, shape=(3, 4), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 那么对于[1, 4]和[3, 1]的两个矩阵，是否可以broadcasting呢？事实上也是可以的\n",
    "a = tf.range(4)\n",
    "b = tf.range(3)\n",
    "b = tf.reshape(b, [3, 1])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数学运算\n",
    "### 加减乘除\n",
    "- 加  +\n",
    "- 减  - \n",
    "- 乘  *\n",
    "- 除  /\n",
    "- 整除  //\n",
    "- 余除  %\n",
    "- 乘方  **\n",
    "- 平方  tf.square()\n",
    "- 平方根  tf.sqrt()\n",
    "- 指数  tf.pow(a, x)或**\n",
    "- 自然指数  tf.exp(x)\n",
    "- 对数  tf.math.log(x)\n",
    "- 矩阵相乘  @或者tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=178, shape=(2, 3), dtype=int32, numpy=\n",
       " array([[ 3,  4,  5],\n",
       "        [ 9, 14, 19]])>,\n",
       " <tf.Tensor: id=179, shape=(2, 3), dtype=int32, numpy=\n",
       " array([[ 3,  4,  5],\n",
       "        [ 9, 14, 19]])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(4), [2, 2])\n",
    "b = tf.reshape(tf.range(6), [2, 3])\n",
    "a @ b, tf.matmul(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
