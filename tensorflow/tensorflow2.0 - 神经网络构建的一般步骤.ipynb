{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看版本\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "### 建立一个单层的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv('E:\\我的学习笔记\\\\tensorflow\\education.csv')\n",
    "data.pop(' ')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.Education  # x是输入数据\n",
    "y = data.Income     # y是目标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个模型\n",
    "# Sequential代表是一个顺序模型\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 顺序模型：一个输入和一个输出的模型，单个积木一层一层搭建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在模型中添加一层\n",
    "model.add(tf.keras.layers.Dense(1, input_shape = (1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这一层是dense层，第一个参数1表示这一层的输出数据的维度，这里是1维，第二个参数表示输入数据的维度，是元组形式，这里是1维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看这个模型的整体信息\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 其中Output Shape中，None是指输入样本的个数，1表示输出的维度。Param表示参数的个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给这个模型进行配置\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'mse'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 告诉这个模型我们要用adam的梯度下降法以及用mse的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练模型并记录模型训练过程\n",
    "history = model.fit(x, y, epochs = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入数据是x，目标数据是y，epochs代表迭代次数，history可以存储运行过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测\n",
    "model.predict(pd.Series([20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立一个两层的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([tf.keras.layers.Dense(10, input_shape = (2,), activation = 'relu'),\n",
    "                               tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里可以直接在Sequential中使用列表的形式来添加层，第一层我们添加10个神经元，因此输出也是10，输入数据是一个2维的数据，需要一个激活函数，使用relu；第二层输出为1个，因为只需要第一个隐藏层有输入就可以了，因此第二层不需要配置input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一层有30个参数，因为对于每个神经元，每个输入维度都有一个权值，所以每个神经元都有2个权值，再加一个偏置，就是3个，一共10个神经元，则一共有30个\n",
    "- 同样对于第二层，有10个输入，每个输入一个权重，再加一个偏置，一共11个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer = 'adam',\n",
    "                loss = 'mse'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\data\\second hand car price prediction\\\\used_car_train_20200313.csv',sep = ' ', nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['power'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['power', 'v_8']]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['price']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(x, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = x.iloc[:10,:]\n",
    "test_y = y.iloc[:10,:]\n",
    "model_2.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当然这里只是举一个例子，因此预测并不准确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是二分类问题，我们可以在最后的一层使用sigmoid函数进行激活\n",
    "model_3.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在使用sigmoid激活函数时，其损失函数最好使用交叉熵\n",
    "# metrics参数代表计算什么，是一个列表，这里输入acc，即计算正确率\n",
    "model_3.compile(optimizer = 'adam'\n",
    "              loss = 'binary_crossentropy'\n",
    "              metrics = ['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在模型训练完成后，我们可以查看模型中计算的变量有哪些\n",
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以通过plt来进行画图\n",
    "# history.epoch就是迭代数， 通过get可以得到loss每个迭代的值\n",
    "plt.plot(history.epoch, history.history.get('loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax\n",
    "### 顺序编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载自带的数据集，注意需要网络\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们使用mnist数据集\n",
    "data = pd.read_csv('E:\\我的学习笔记\\统计学习方法\\实战\\训练数据\\\\mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data.iloc[0:55000,1:]\n",
    "train_y = data.iloc[0:55000,0:1]\n",
    "test_x = data.iloc[55000:,1:]\n",
    "test_y = data.iloc[55000:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = tf.keras.Sequential()\n",
    "\n",
    "# 对二维输入数据flatten至一维，但因为mnist中本来就已经为一维数据\n",
    "# 因此不需要flatten\n",
    "# model_4.add(tf.keras.layers.Flatten(input_shape = (28, 28)))\n",
    "\n",
    "# 第二层\n",
    "model_4.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "\n",
    "# 第三层，使用softmax\n",
    "model_4.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当最后的分类为数字顺序编码，我们的loss使用sparse_categorical_crossentropy\n",
    "model_4.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为tensorflow无法直接handle dataframe的数据，因此将其转换成ndarray\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.fit(train_x, train_y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过测试集对模型进行测试\n",
    "model_4.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将train_y改成独热编码\n",
    "train_y_onehot = tf.keras.utils.to_categorical(train_y)\n",
    "test_y_onehot = tf.keras.utils.to_categorical(test_y)\n",
    "print(train_y_onehot.shape, test_y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = tf.keras.Sequential()\n",
    "\n",
    "# 第一层\n",
    "model_5.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "\n",
    "# 第二层，使用softmax\n",
    "model_5.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# 当最后的分类为独热编码，我们的loss使用categorical_crossentropy\n",
    "model_5.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.fit(train_x, train_y_onehot, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.evaluate(test_x, test_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何改变优化器的学习速率等参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变学习速率，可以在对模型进行compile的过程中改变\n",
    "model_5.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何提高网络拟合能力\n",
    "- 可以增加神经元个数\n",
    "- 可以增加层数\n",
    "- 一般增加层数可以更好的提高拟合能力，但是有可能过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用dropout抑制过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们可以在训练模型的每一次迭代中都对测试集进行预测\n",
    "model_6 = tf.keras.Sequential()\n",
    "\n",
    "# 这里我们多加几层，造成过拟合\n",
    "model_6.add(tf.keras.layers.Dense(128, input_shape = (784, ), \n",
    "                                  activation = 'relu')\n",
    "           )\n",
    "model_6.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model_6.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model_6.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "# 第二层，使用softmax\n",
    "model_6.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# 当最后的分类为独热编码，我们的loss使用categorical_crossentropy\n",
    "model_6.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc']\n",
    "             )\n",
    "\n",
    "# 在这里加入validation_data就可以得到每次迭代的预测结果\n",
    "history = model_6.fit(train_x, train_y_onehot, epochs = 10,\n",
    "            validation_data = (test_x, test_y_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看到结果中出现了val_loss和val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history.get('loss'), label = 'loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), label = 'acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), label = 'acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这时发现loss一直在降低，但是validation_data的loss并没有\n",
    "- 发现acc一直在上升，但是validation_data的acc并没有\n",
    "- 这是过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们在上一个模型的基础上，添加dropout\n",
    "model_7 = tf.keras.Sequential()\n",
    "\n",
    "# 这里层数过多，造成过拟合\n",
    "model_7.add(tf.keras.layers.Dense(128, input_shape = (784, ), \n",
    "                                  activation = 'relu')\n",
    "           )\n",
    "model_7.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "\n",
    "# 我们可以随意的在各层之间添加dropout，0.5表示dropout的概率\n",
    "model_7.add(tf.keras.layers.Dropout(0.5))\n",
    "model_7.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model_7.add(tf.keras.layers.Dropout(0.5))\n",
    "model_7.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model_7.add(tf.keras.layers.Dropout(0.5))\n",
    "model_7.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# 当最后的分类为独热编码，我们的loss使用categorical_crossentropy\n",
    "model_7.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc']\n",
    "             )\n",
    "\n",
    "# 在这里加入validation_data就可以得到每次迭代的预测结果\n",
    "history = model_7.fit(train_x, train_y_onehot, epochs = 10,\n",
    "            validation_data = (test_x, test_y_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history.get('loss'), label = 'loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), label = 'val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history.get('acc'), label = 'acc')\n",
    "plt.plot(history.epoch, history.history.get('val_acc'), label = 'acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 我们发现val_loss下降了，同时val_acc也上升了\n",
    " - 当然我们也可以通过减少神经网络的规模规避过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数式API\n",
    "- 可以将每一层当作一个函数来建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (784, ))\n",
    "x = tf.keras.layers.Dense(32, activation = 'relu')(inputs)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数式API可以得到一个更复杂的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比如可以有两个输入，一个输出\n",
    "input1 = tf.keras.Input(shape = (784, ))\n",
    "input2 = tf.keras.Input(shape = (784, ))\n",
    "x = tf.keras.layers.concatenate([input1, input2])\n",
    "x = tf.keras.layers.Dense(32, activation = 'relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "model = tf.keras.Model(inputs = [input1, input2], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
